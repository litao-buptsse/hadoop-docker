<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->    
<configuration>
     <property>
      <name>dfs.balancer.moverThreads</name>
      <value>1000</value>
    </property>
     <property>
      <name>dfs.balancer.dispatcherThreads</name>
      <value>50</value>
    </property> 
    <property>
      <name>dfs.namenode.checkpoint.period</name>
      <value>7200</value>
    </property>

    <property>
      <name>dfs.qjournal.write-txns.timeout.ms</name>
      <value>110000</value>
    </property>

    <property>
      <name>dfs.namenode.avoid.write.stale.datanode</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.namenode.checkpoint.txns</name>
      <value>1000000</value>
    </property>
    
    <property>
      <name>dfs.block.access.token.enable</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.support.append</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.datanode.address</name>
      <value>0.0.0.0:50010</value>
    </property>
    
    <property>
      <name>dfs.cluster.administrators</name>
      <value> hdfs</value>
    </property>
    
    <property>
      <name>dfs.replication</name>
      <value>3</value>
    </property>
    
    <property>
      <name>dfs.datanode.balance.bandwidthPerSec</name>
      <value>300000000</value>
    </property>

    <property>
      <name>dfs.namenode.safemode.threshold-pct</name>
      <value>0.99f</value>
    </property>
    
    <property>
      <name>dfs.namenode.checkpoint.edits.dir</name>
      <value>${dfs.namenode.checkpoint.dir}</value>
    </property>
    
    <property>
      <name>dfs.permissions.enabled</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.client.read.shortcircuit</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.namenode.https-address</name>
      <value>${master1}:50470</value>
    </property>
    
    <property>
      <name>dfs.journalnode.edits.dir</name>
      <value>/search/data/journal</value>
    </property>
    
    <property>
      <name>dfs.blocksize</name>
      <value>536870912</value>
    </property>
    
    <property>
      <name>dfs.datanode.du.reserved</name>
      <!--value>1073741824</value-->
      <value>96636764160</value>
    </property>
    
    <property>
      <name>dfs.webhdfs.enabled</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.namenode.handler.count</name>
      <value>256</value>
    </property>

    <property>
      <name>dfs.datanode.handler.count</name>
      <value>120</value>
      <description>The number of server threads for the datanode.</description>
    </property>
    
    <property>
      <name>dfs.namenode.checkpoint.dir</name>
      <value>/search/data/namesecondary</value>
    </property>
    
    <property>
      <name>fs.permissions.umask-mode</name>
      <value>022</value>
    </property>
    
    <property>
      <name>dfs.datanode.http.address</name>
      <value>0.0.0.0:50075</value>
    </property>
    
    <property>
      <name>dfs.datanode.ipc.address</name>
      <value>0.0.0.0:8010</value>
    </property>
    
    <property>
      <name>dfs.datanode.data.dir</name>
            <value>file:///search/data/dfs_data</value>
          </property>
    
    <!--property>
      <name>dfs.namenode.http-address</name>
      <value>${master1}:50070</value>
    </property-->
    
    <property>
      <name>dfs.blockreport.initialDelay</name>
      <value>120</value>
    </property>
    
    <property>
      <name>dfs.datanode.failed.volumes.tolerated</name>
            <value>5</value>
          </property>
    
    <property>
      <name>dfs.namenode.accesstime.precision</name>
      <value>3600000</value>
    </property>
    
    <property>
      <name>dfs.namenode.avoid.read.stale.datanode</name>
      <value>true</value>
    </property>
    
    <!--property>
      <name>dfs.namenode.secondary.http-address</name>
      <value>${local.namenode.secondary}:50090</value>
    </property-->
    
    <property>
      <name>dfs.namenode.stale.datanode.interval</name>
      <value>30000</value>
    </property>
    
    <property>
      <name>dfs.heartbeat.interval</name>
      <value>3</value>
    </property>
    
    <property>
      <name>dfs.client.read.shortcircuit.streams.cache.size</name>
      <value>100</value>
    </property>
   
    <property>
      <name>dfs.permissions.superusergroup</name>
      <value>hdfs</value>
    </property>
    
    <property>
      <name>dfs.https.port</name>
      <value>50470</value>
    </property>
    
    <property>
      <name>dfs.journalnode.http-address</name>
      <value>0.0.0.0:8480</value>
    </property>
    
<!--
    <property>
      <name>dfs.domain.socket.path</name>
      <value>/var/lib/hadoop-hdfs/dn_socket</value>
    </property>
-->
    
    <property>
      <name>dfs.namenode.write.stale.datanode.ratio</name>
      <value>1.0f</value>
    </property>
    
    <property>
      <name>dfs.hosts.exclude</name>
      <value>/search/hadoop/etc/hadoop/exclude_dn_hosts</value>
    </property>
    
    <property>
      <name>dfs.datanode.data.dir.perm</name>
      <value>750</value>
    </property>
    
    <property>
      <name>dfs.namenode.name.dir.restore</name>
      <value>true</value>
    </property>
    
    <property>
      <name>dfs.replication.max</name>
      <value>50</value>
    </property>
    
    <property>
      <name>dfs.namenode.name.dir</name>
      <value>/search/data/dfs_name</value>
    </property>
 
    <!--for namenode ha-->
        <property>
      <name>dfs.nameservices</name>
            <value>ns1,ns2</value>
          </property>

    <property>
      <name>dfs.ha.namenodes.ns1</name>
      <value>nn1,nn2</value>
    </property>
   
    <property>
      <name>dfs.namenode.rpc-address.ns1.nn1</name>
      <value>${master1}:8020</value>
    </property>
   
    <property>
      <name>dfs.namenode.rpc-address.ns1.nn2</name>
      <value>${master2}:8020</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.ns1.nn1</name>
      <value>${master1}:50070</value>
    </property>
    <property>
       <name>dfs.namenode.http-address.ns1.nn2</name>
      <value>${master2}:50070</value>
    </property>
   
    <property>
      <name>dfs.namenode.shared.edits.dir</name>
      <value>qjournal://${local.journalnode}/${namespace}</value>
    </property> 
  
    <property>
      <name>dfs.client.failover.proxy.provider.ns1</name>
      <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

        <property>
      <name>dfs.ha.namenodes.ns2</name>
      <value>nn3,nn4</value>
    </property>

    <property>
      <name>dfs.namenode.rpc-address.ns2.nn3</name>
      <value>${master3}:8020</value>
    </property>

    <property>
      <name>dfs.namenode.rpc-address.ns2.nn4</name>
      <value>${master4}:8020</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.ns2.nn3</name>
      <value>${master3}:50070</value>
    </property>
    <property>
       <name>dfs.namenode.http-address.ns2.nn4</name>
      <value>${master4}:50070</value>
    </property>

    <property>
      <name>dfs.client.failover.proxy.provider.ns2</name>
      <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
     
    <property>
      <name>dfs.ha.fencing.methods</name>
      <value>shell(/bin/true)</value>
    </property>
  
    <property>
      <name>dfs.ha.automatic-failover.enabled</name>
      <value>true</value>
    </property>
  
        

    <property>
      <name>hadoop.client.ugi</name>
      <value>hdfs,hdfspassword180</value>
    </property>

   <property>
      <name>dfs.namenode.num.checkpoints.retained</name>
      <value>1</value>
   </property>

   <property>
     <name>ha.health-monitor.rpc-timeout.ms</name>
     <value>180000</value>
   </property>

   <!-- ##### Section 2: hadoop security setting end.                     ##### -->
  <!-- ####################################################################### -->

  <!-- ####################################################################### -->
  <!-- ##### Section 3: hdfs raid setting                                ##### -->

  <property>
    <name>raid.config.file</name>
    <value>/search/hadoop/etc/hadoop/raid.xml</value>
    <description>raid configuration file location </description>
  </property>

  <property>
    <name>raid.classname</name>
    <value>org.apache.hadoop.raid.DistRaidNode</value>
    <description>Specify which implementation of RaidNode to use
                 (class name).
    </description>
  </property>

  <property>
    <name>raid.keytab.file</name>
    <value>/search/hadoop/etc/hadoop/raid.keytab</value>
    <description>keytab file used to run raid </description>
  </property>

  <property>
    <name>raid.user.name</name>
    <value>raid</value>
    <description>user name used to run raid </description>
  </property>

  <property>
    <name>raid.shell.keytab.file</name>
    <value>/search/hadoop/etc/hadoop/hdfs.keytab</value>
    <description>keytab file used to run raid shell </description>
  </property>

  <property>
    <name>raid.shell.user.name</name>
    <value>hdfs/cloud101417580.wd.nm.ss.nop.sogou-op.org</value>
    <description>user name used to run raid shell </description>
  </property>

  <property>
    <name>raid.blockfixer.user.name</name>
    <value>raid</value>
    <final>true</final>
    <description>user name used to run raid block fixer </description>
  </property>

  <property>
    <name>raid.policy.rescan.interval</name>
    <value>43200000</value>
    <description>The interval between two times of scan to do the raid </description>
  </property>

	<property>
		<name>raid.blockfix.history.interval</name>
		<value>25200000</value>
	<description>Block fix history interval,because dn report interval is 6 houres.So set it 7 houres</description>
	</property>
	
  <property>
    <name>hdfs.raid.stripeLength</name>
    <value>10</value>
    <description>The stripe length used to doing the raid, which means
                 using each stripelength blocks to generating one parity block.
    </description>
  </property>

  <property>
    <name>raid.server.address</name>
    <value>localhost:41234</value>
    <description>The raid server address, used to listen the request sent to server.
    </description>
  </property>

  <!--property>
    <name>fs.hdfs.impl</name>
    <value>org.apache.hadoop.hdfs.DistributedRaidFileSystem</value>
    <description>The FileSystem for hdfs: uris.</description>
  </property-->

  <property>
    <name>hdfs.raidrs.paritylength</name>
    <value>2</value>
    <description>The parity length for Reed Solomon mechanism</description>
  </property>

  <property>
    <name>hdfs.raid.locations</name>
    <value>/raid</value>
    <description>The location to storing the parity files generated by XOR mechanism</description>
  </property>

  <property>
    <name>hdfs.raidrs.locations</name>
    <value>/raidrs</value>
    <description>The location to storing the parity files generated by Reed Solomon mechanism</description>
  </property>

  <property>
    <name>raid.blockfix.classname</name>
    <value>org.apache.hadoop.raid.DistBlockFixer</value>
    <description>The class used to doing the block fixing</description>
  </property> 

  <property>
    <name>hdfs.use.df.check.usage</name>
    <value>true</value>
  </property>  
  
</configuration>
